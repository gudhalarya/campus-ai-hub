#!/usr/bin/env bash
set -euo pipefail

ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
RUNTIME_ENV="$ROOT_DIR/infra/runtime.env"
COMPOSE_FILE="$ROOT_DIR/infra/docker-compose.runtime.yml"

MODE="auto"
START_STACK=1

usage() {
  cat <<USAGE
Usage: ./setup [--auto|--local|--cloud] [--no-start]

Options:
  --auto      Detect machine and auto-select mode (default)
  --local     Force local/offline runtime mode
  --cloud     Force cloud/API runtime mode
  --no-start  Only generate config, do not start containers
  -h, --help  Show this help
USAGE
}

while [[ $# -gt 0 ]]; do
  case "$1" in
    --auto) MODE="auto" ;;
    --local) MODE="local" ;;
    --cloud) MODE="cloud" ;;
    --no-start) START_STACK=0 ;;
    -h|--help) usage; exit 0 ;;
    *)
      echo "Unknown argument: $1" >&2
      usage
      exit 1
      ;;
  esac
  shift
done

have_cmd() {
  command -v "$1" >/dev/null 2>&1
}

detect_cores() {
  if have_cmd nproc; then
    nproc
    return
  fi

  if [[ "$(uname -s)" == "Darwin" ]]; then
    sysctl -n hw.logicalcpu
    return
  fi

  echo 2
}

detect_ram_mb() {
  if [[ -r /proc/meminfo ]]; then
    awk '/MemTotal/ {print int($2/1024)}' /proc/meminfo
    return
  fi

  if [[ "$(uname -s)" == "Darwin" ]]; then
    local bytes
    bytes="$(sysctl -n hw.memsize)"
    echo $((bytes / 1024 / 1024))
    return
  fi

  echo 4096
}

machine_class() {
  local cores="$1"
  local ram_mb="$2"

  if (( cores < 2 || ram_mb < 4096 )); then
    echo "extreme"
  elif (( cores < 4 || ram_mb < 8192 )); then
    echo "low"
  elif (( cores < 8 || ram_mb < 16384 )); then
    echo "mid"
  else
    echo "high"
  fi
}

recommend_model() {
  local class="$1"
  case "$class" in
    low) echo "qwen2.5:1.5b" ;;
    mid) echo "qwen2.5:3b" ;;
    high) echo "qwen2.5:7b" ;;
    *) echo "" ;;
  esac
}

recommend_threads() {
  local cores="$1"
  if (( cores <= 2 )); then
    echo 1
  elif (( cores <= 4 )); then
    echo 2
  elif (( cores <= 8 )); then
    echo 4
  else
    echo 6
  fi
}

recommend_parallel() {
  local class="$1"
  case "$class" in
    low|mid) echo 1 ;;
    high) echo 2 ;;
    *) echo 1 ;;
  esac
}

CORES="$(detect_cores)"
RAM_MB="$(detect_ram_mb)"
ARCH="$(uname -m)"
CLASS="$(machine_class "$CORES" "$RAM_MB")"

if [[ "$MODE" == "auto" ]]; then
  if [[ "$CLASS" == "extreme" ]]; then
    RESOLVED_MODE="cloud"
  else
    RESOLVED_MODE="local"
  fi
else
  RESOLVED_MODE="$MODE"
fi

OLLAMA_MODEL="$(recommend_model "$CLASS")"
OLLAMA_NUM_THREADS="$(recommend_threads "$CORES")"
OLLAMA_NUM_PARALLEL="$(recommend_parallel "$CLASS")"
OLLAMA_MAX_LOADED_MODELS=1
OLLAMA_KEEP_ALIVE="2m"

if [[ "$RESOLVED_MODE" == "cloud" ]]; then
  OLLAMA_MODEL=""
fi

mkdir -p "$ROOT_DIR/data/models"

cat > "$RUNTIME_ENV" <<ENV
# Auto-generated by ./setup on $(date -u +"%Y-%m-%dT%H:%M:%SZ")
MODE=$RESOLVED_MODE
PORT=8000
LOCAL_MODEL_BASE_URL=http://local-model:11434
OLLAMA_MODEL=${OLLAMA_MODEL}
OLLAMA_NUM_THREADS=${OLLAMA_NUM_THREADS}
OLLAMA_NUM_PARALLEL=${OLLAMA_NUM_PARALLEL}
OLLAMA_MAX_LOADED_MODELS=${OLLAMA_MAX_LOADED_MODELS}
OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE}
CLOUD_API_BASE_URL=https://api.openai.com/v1
CLOUD_MODEL=gpt-4.1-mini
# Set before cloud runs:
CLOUD_API_KEY=${CLOUD_API_KEY:-}

# Detection metadata
MACHINE_ARCH=${ARCH}
MACHINE_CLASS=${CLASS}
CPU_CORES=${CORES}
RAM_MB=${RAM_MB}
ENV

echo ""
echo "Machine detection summary"
echo "  Architecture : $ARCH"
echo "  CPU cores    : $CORES"
echo "  RAM (MB)     : $RAM_MB"
echo "  Class        : $CLASS"
echo "  Mode         : $RESOLVED_MODE"
if [[ "$RESOLVED_MODE" == "local" ]]; then
  echo "  Local model  : $OLLAMA_MODEL"
  echo "  Threads      : $OLLAMA_NUM_THREADS"
  echo "  Parallel req : $OLLAMA_NUM_PARALLEL"
fi

echo ""
echo "Wrote optimized runtime config: $RUNTIME_ENV"

if (( START_STACK == 0 )); then
  echo "Skipping container startup (--no-start)."
  exit 0
fi

if ! have_cmd docker; then
  echo "Docker not found. Install Docker and run:"
  echo "  docker compose -f infra/docker-compose.runtime.yml --profile $RESOLVED_MODE up -d --build"
  exit 0
fi

if ! docker info >/dev/null 2>&1; then
  echo "Docker daemon is not available. Start Docker and then run:"
  echo "  docker compose -f infra/docker-compose.runtime.yml --profile $RESOLVED_MODE up -d --build"
  exit 0
fi

echo ""
echo "Starting optimized container stack..."
docker compose -f "$COMPOSE_FILE" --profile "$RESOLVED_MODE" up -d --build

echo ""
echo "Stack started."
echo "  Web: http://localhost:8080"
echo "  API: http://localhost:8000/health"
if [[ "$RESOLVED_MODE" == "local" ]]; then
  echo "  Model runtime: http://localhost:11434"
else
  echo "  Cloud mode enabled. Set CLOUD_API_KEY in infra/runtime.env if not set."
fi
